{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import string\n",
    "import numpy as np\n",
    "import nltk\n",
    "import json\n",
    "import numpy as np\n",
    "# Python program to generate WordCloud\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "# import matplotlib as mpl\n",
    "# mpl.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vulgar Words List\n",
    "vulgar_words_lst = []\n",
    "with open('vulgar_words.txt', mode='r') as f:\n",
    "    contents_vulgar_words = f.readlines()\n",
    "    for words in contents_vulgar_words:\n",
    "        words = words.replace('\\n', '')\n",
    "        vulgar_words_lst.append(words)\n",
    "\n",
    "## Setting up stopwords\n",
    "stopwords = set(STOPWORDS)\n",
    "\n",
    "## Pronouns List\n",
    "pronouns_lst = []\n",
    "with open('pronouns.txt', mode='r') as f:\n",
    "    contents_pronoun_words = f.readlines()\n",
    "    for words in contents_pronoun_words:\n",
    "        words = words.replace('\\n', '')\n",
    "        pronouns_lst.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load manifesto data\n",
    "with open(\"manifesto-data.json\", 'r') as f:\n",
    "    manifesto_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Manifesto(object):\n",
    "    def __init__(self, author, title, manifesto_data):\n",
    "        self.manifesto_word_lst = []\n",
    "        self.author = author\n",
    "        self.manifesto = manifesto_data[author][title]\n",
    "\n",
    "        # cleaning data\n",
    "        self.manifesto_clean = \"\".join((char for char in self.manifesto if char not in string.punctuation))\n",
    "        self.tokens = self.manifesto_clean.split()\n",
    "        for i in range (len(self.tokens)):\n",
    "            self.tokens[i] = self.tokens[i].lower()\n",
    "            self.manifesto_word_lst.append(self.tokens[i])\n",
    "\n",
    "        # get rid of stopwords\n",
    "        self.filtered_manifesto = [w for w in self.tokens if not w in stopwords]\n",
    "        self.filtered_manifesto = [] ## No stopwords\n",
    "        for w in self.tokens:\n",
    "            if w not in stopwords:\n",
    "                self.filtered_manifesto.append(w)\n",
    "\n",
    "        # unique words\n",
    "        self.unique_words_lst = []\n",
    "        for word in self.manifesto_word_lst:\n",
    "            if word not in self.unique_words_lst:\n",
    "                self.unique_words_lst.append(word)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    def __str__(self):\n",
    "        return '{}, {}'.format(self.author, self.manifesto)\n",
    "\n",
    "    def word_lst(self): ## returns self.manifesto_word_lst to be used for specific data analysis (such as using pandas)\n",
    "        return self.manifesto_word_lst\n",
    "\n",
    "    ## returns unique words to be used for specific data analysis (such as using pandas)\n",
    "    def unique_words(self):\n",
    "        return self.unique_words_lst\n",
    "\n",
    "    ## Word Cloud Function\n",
    "    def word_cloud(self):\n",
    "        comment_words = ' '\n",
    "        for words in self.tokens:\n",
    "            comment_words = comment_words + words + ' '\n",
    "\n",
    "        wordcloud = WordCloud(width = 800, height = 800,\n",
    "                        background_color ='black',\n",
    "                        stopwords = stopwords,\n",
    "                        min_font_size = 10).generate(comment_words)\n",
    "        # plot the WordCloud image\n",
    "        plt.figure(figsize = (8, 8), facecolor = None)\n",
    "        plt.imshow(wordcloud,  interpolation=\"bilinear\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.tight_layout(pad = 0)\n",
    "        plt.show()\n",
    "\n",
    "    ## Vulgar Words Function\n",
    "    def vulgar_words(self):\n",
    "        vulgar_words = ' '\n",
    "        for vulgar_word in vulgar_words_lst:\n",
    "            if vulgar_word in self.filtered_manifesto:\n",
    "                vulgar_words = vulgar_words + vulgar_word + ' '\n",
    "\n",
    "        wordcloud = WordCloud(width = 800, height = 800,\n",
    "                        background_color ='black',\n",
    "                        min_font_size = 10).generate(vulgar_words)\n",
    "        # plot the WordCloud image\n",
    "        plt.figure(figsize = (8, 8), facecolor = None)\n",
    "        plt.imshow(wordcloud,  interpolation=\"bilinear\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.tight_layout(pad = 0)\n",
    "        plt.show()\n",
    "\n",
    "    ## Sentiment Analysis functions ##\n",
    "    def sentiment_analysis(self):\n",
    "        sia = SIA()\n",
    "        self.results = []\n",
    "\n",
    "        for line in self.filtered_manifesto:\n",
    "            pol_score = sia.polarity_scores(line)\n",
    "            pol_score['word'] = line\n",
    "            self.results.append(pol_score)\n",
    "\n",
    "        df = pd.DataFrame.from_records(self.results)\n",
    "        df.head()\n",
    "\n",
    "        df['label'] = 0\n",
    "        df.loc[df['compound'] > 0.2, 'label'] = 1\n",
    "        df.loc[df['compound'] < -0.2, 'label'] = -1\n",
    "        df.head()\n",
    "\n",
    "        df.label.value_counts(normalize=True) * 100\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "        counts = df.label.value_counts(normalize=True) * 100\n",
    "\n",
    "        x = counts.index\n",
    "        y = counts\n",
    "        ax.set_ylabel('Percentage')\n",
    "        ax.set_title('Sentiment Analysis')\n",
    "        rects = plt.bar(x, y)\n",
    "        plt.xticks(x, (\"Neutral\", \"Negative\", \"Positive\"))\n",
    "\n",
    "\n",
    "        def autolabel(rects, xpos='center'):\n",
    "            xpos = xpos.lower()  # normalize the case of the parameter\n",
    "            ha = {'center': 'center', 'right': 'left', 'left': 'right'}\n",
    "            offset = {'center': 0.5, 'right': 0.57, 'left': 0.43}  # x_txt = x + w*off\n",
    "\n",
    "            for rect in rects:\n",
    "                height = rect.get_height()\n",
    "                ax.text(rect.get_x() + rect.get_width()*offset[xpos], 1.01*height,\n",
    "                        '{}'.format(height), ha=ha[xpos], va='bottom', fontsize=9)\n",
    "\n",
    "        autolabel(rects)\n",
    "        plt.tight_layout(pad = 1)\n",
    "        plt.show()\n",
    "\n",
    "    ## Pronoun Functions ##\n",
    "    def pronouns_analysis(self):\n",
    "        pronouns = ' '\n",
    "        for pronoun in pronouns_lst:\n",
    "            if pronoun in self.manifesto_word_lst: ## not filtered\n",
    "                pronouns = pronouns + pronoun + ' '\n",
    "\n",
    "        wordcloud = WordCloud(width = 800, height = 800,\n",
    "                        background_color ='black',\n",
    "                        min_font_size = 10).generate(pronouns)\n",
    "        # plot the WordCloud image\n",
    "        plt.figure(figsize = (8, 8), facecolor = None)\n",
    "        plt.imshow(wordcloud,  interpolation=\"bilinear\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.tight_layout(pad = 0)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Word Count Functions ##\n",
    "## Please make sure manifesto variable names matches DataFrame. Sorry I couldn't figure out the best way to solve this right now.\n",
    "def word_count():\n",
    "    df=pd.DataFrame({'Authors': [ 'Adkisson', 'Auvinen', 'Cho', 'Dorner', 'Kaczynski', 'Rodger', 'Roof'],\n",
    "                     'Number of Words': [len(adkisson.word_lst()),len(auvinen.word_lst()),len(cho.word_lst()),len(dorner.word_lst()),len(kaczynski.word_lst()),len(rodger.word_lst()),len(roof.word_lst())],})\n",
    "\n",
    "    df = df.set_index('Authors')\n",
    "    ax = df.plot(kind='bar',  title='Total Words in Manifesto')\n",
    "    ax.set_ylabel('Number of Words')\n",
    "    ax.set_ylim(0, 130000)\n",
    "    for i, label in enumerate(list(df.index)):\n",
    "        score = df.ix[label]['Number of Words']\n",
    "        ax.annotate(str(score), (i-0.299, score + 0.04), fontsize=9)\n",
    "    plt.tight_layout(pad = 1)\n",
    "    plt.show()\n",
    "\n",
    "def unique_words():\n",
    "    original = (len(adkisson.word_lst()),len(auvinen.word_lst()),len(cho.word_lst()),len(dorner.word_lst()),len(kaczynski.word_lst()),len(rodger.word_lst()),len(roof.word_lst()))\n",
    "    unique_words = (len(adkisson.unique_words()),len(auvinen.unique_words()),len(cho.unique_words()),len(dorner.unique_words()),len(kaczynski.unique_words()),len(rodger.unique_words()),len(roof.unique_words()))\n",
    "\n",
    "    ind = np.arange(len(original))  # the x locations for the groups\n",
    "    width = 0.43  # the width of the bars\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    rects1 = ax.bar(ind - width/2, original, width,\n",
    "                    color='SkyBlue', label='Original')\n",
    "    rects2 = ax.bar(ind + width/2, unique_words, width,\n",
    "                    color='IndianRed', label='Unique Words')\n",
    "\n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax.set_ylabel('Number of Words')\n",
    "    ax.set_title('Orignal text vs. unique words')\n",
    "    ax.set_xticks(ind)\n",
    "    ax.set_xticklabels(('Adkisson', 'Auvinen', 'Cho', 'Dorner', 'Kaczynski', 'Rodger', 'Roof'))\n",
    "    ax.legend()\n",
    "\n",
    "    def autolabel(rects, xpos='center'):\n",
    "        xpos = xpos.lower()  # normalize the case of the parameter\n",
    "        ha = {'center': 'center', 'right': 'left', 'left': 'right'}\n",
    "        offset = {'center': 0.5, 'right': 0.57, 'left': 0.43}  # x_txt = x + w*off\n",
    "\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.text(rect.get_x() + rect.get_width()*offset[xpos], 1.01*height,\n",
    "                    '{}'.format(height), ha=ha[xpos], va='bottom', fontsize=6.5)\n",
    "\n",
    "    autolabel(rects1)\n",
    "    autolabel(rects2)\n",
    "    plt.tight_layout(pad = 1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
